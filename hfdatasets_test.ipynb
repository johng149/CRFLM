{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/john/Secondary/Projects/ML/CRFLM/crf/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"databricks/databricks-dolly-15k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all where 'category' is 'closed_qa'\n",
    "closed = training_set.filter(lambda x: x[\"category\"] == \"closed_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'context', 'response', 'category'],\n",
       "    num_rows: 1773\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_dataset(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train, squad_val = squad[\"train\"], squad[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = squad_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend \"Venite Ad Me Omnes\". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.',\n",
       " 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?',\n",
       " 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_answer = sample[\"answers\"][\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saint Bernadette Soubirous'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenmonster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_file = \"english-8000-balanced-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenmonster.load_multiprocess_safe(tokenizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1154, 3453, 3109,  707,   68, 2463,   63, 5980,  745,  538, 1398],\n",
       "      dtype=uint16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.tokenize(\"the quick brown fox jumps over the lazy dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the issue with this is that the dtype is numpy.uint16 is returned by\n",
    "# tokenizer, while we expect torch int32\n",
    "result = vocab.tokenize(\"the quick brown fox jumps over the lazy dog\")\n",
    "result = result.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1154, 3453, 3109,  707,   68, 2463,   63, 5980,  745,  538, 1398],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab.decode([326, 1642, 33, 8001, 45])\n",
    "# vocab size is only 8000, so the 8001 is skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sample):\n",
    "    context, question, answer = sample[\"context\"], sample[\"question\"], sample[\"answers\"][\"text\"][0]\n",
    "    context_tokens = vocab.tokenize(context)\n",
    "    question_tokens = vocab.tokenize(question)\n",
    "    answer_tokens = vocab.tokenize(answer)\n",
    "    return {\n",
    "        \"context\": context_tokens.astype(\"int32\"),\n",
    "        \"question\": question_tokens.astype(\"int32\"),\n",
    "        \"answers\": answer_tokens.astype(\"int32\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 87599/87599 [01:09<00:00, 1267.76 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_squad_train = squad_train.map(tokenize).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'title', 'context', 'question', 'answers'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_squad_train[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'When did Virgin Australia start operating?',\n",
       " 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\",\n",
       " 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.',\n",
       " 'category': 'closed_qa'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_closed(sample):\n",
    "    context, question, response = sample[\"context\"], sample[\"instruction\"], sample[\"response\"]\n",
    "    context_tokens = vocab.tokenize(context)\n",
    "    question_tokens = vocab.tokenize(question)\n",
    "    response_tokens = vocab.tokenize(response)\n",
    "    return {\n",
    "        \"context\": context_tokens.astype(\"int32\"),\n",
    "        \"instruction\": question_tokens.astype(\"int32\"),\n",
    "        \"response\": response_tokens.astype(\"int32\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   7%|▋         | 119/1773 [00:00<00:01, 1152.91 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1773/1773 [00:01<00:00, 899.31 examples/s] \n"
     ]
    }
   ],
   "source": [
    "tokenized_closed = closed.map(tokenize_closed).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 87599/87599 [00:00<00:00, 445742.75 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1773/1773 [00:00<00:00, 137010.17 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_squad_train.save_to_disk(data_dir + \"/squad_train\")\n",
    "tokenized_closed.save_to_disk(data_dir + \"/closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset to see if it works\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_squad_train = load_from_disk(data_dir + \"/squad_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "    num_rows: 87599\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_squad_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '5733be284776f41900661182',\n",
       " 'title': 'University_of_Notre_Dame',\n",
       " 'context': tensor([ 332, 6414,  519, 2031, 2829, 4381, 3267, 6871, 6450,  300,  228,   37,\n",
       "         1800, 1788,   36, 2509,   36, 5691,  275, 2389,  683,  445, 2452, 4092,\n",
       "         2695,  515, 4280,   36, 1828,  398,   58, 3755,  300, 7409, 7891,   36,\n",
       "         2509,   36, 5691, 1263, 1440, 3794,   15, 2452, 1358, 1113, 2695,  515,\n",
       "          769, 5501, 2788, 2204,  822,   37, 4341, 6232, 1559, 1006, 1212, 1822,\n",
       "         1061,   36,  645, 1953,  921,   57, 1094,  850, 5132, 1788,   36, 2509,\n",
       "           36, 5691, 4165,   36,  660,   37, 1737, 1038, 4280, 1966,   37, 1363,\n",
       "           48, 1941,   37, 1274,  300, 7409, 6987,  660,   37, 1737, 1038, 4165,\n",
       "           36, 1486,  512,  462,  228, 3753,  349, 3433,  769, 1670,   69, 3787,\n",
       "         7169,  300, 5060, 1697, 1080,   45, 4280, 1486,  512,   59,  655,   36,\n",
       "          239,   37, 1638, 1002,   15, 5506, 6815,   36, 1828,  398,   58, 3755,\n",
       "          789,   37, 1677,  380,  443, 5660,  815, 1966, 1053,   36, 1302,  452,\n",
       "           37, 1386,  507,   36, 1753,  356,  489,  520,  727,  604,   24,   27,\n",
       "          300, 7934, 2509, 3185, 3827, 2443, 4007, 2490, 2725, 4866,   63, 5352,\n",
       "          213, 2695,  515, 6356,   36, 2389, 1937,  445,  281, 2452, 4416,   15,\n",
       "         4240, 3544, 2695,  515,  769, 3755,   17]),\n",
       " 'question': tensor([2903, 2779, 1389, 1788,   36, 1828,  398,   58, 3755, 1256,   37,  690,\n",
       "          380,  443, 3882,  727,  604,   24,   27,  727,   36,  239,   37, 1638,\n",
       "         1002, 5506,   34]),\n",
       " 'answers': tensor([ 332,  793, 1053,   36, 1302,  452,   37, 1386,  507,   36, 1753,  356,\n",
       "          489,  520])}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_squad_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': tensor([ 332, 2778, 1389,   36, 1828,  398,   58, 7280, 3537, 6645,   34]),\n",
       " 'context': tensor([ 332, 1828,  398,   58, 7280, 2829, 1802, 2048, 2543,  769,   36, 1828,\n",
       "          398,   58, 7280,   36, 1252, 2953,  922,  514, 2886,   15, 3305, 7280,\n",
       "           58, 5479, 1252, 2079, 5484, 1788, 5075, 1252, 2079,  668, 1454,  389,\n",
       "         2677,  815, 5390,   36, 1828,  398,   58, 3102, 2856, 2271, 2054,   48,\n",
       "         6078,  772,  618, 5497, 2170,  654,   36, 1828,  398,   58,   36, 2230,\n",
       "         3699, 1810, 1252,   37, 3153, 2561, 4419, 3474, 2856, 6111, 3229, 4178,\n",
       "         2207, 3354, 1252, 2079,  727, 7280,  275, 5764, 4220, 6391, 1355,   37,\n",
       "         1551,  498,  769, 1926, 1138,   64, 7280,  727, 7291, 2171, 3723, 1252,\n",
       "         2079, 1495, 3507, 3257,  815, 5755, 3485,  619, 3961,  727, 7280, 3689,\n",
       "          721,  358,  727,   36, 1324,   63,   37, 1292,   49,  290, 1589,   37,\n",
       "         1318,  488, 2925,   36,  809,   48, 1096,   17]),\n",
       " 'response': tensor([ 332, 1828,  398,   58, 7280, 2271, 2054,   48, 6078,  772,  618, 5497,\n",
       "         2170,  654,   36, 1828,  398,   58,   36, 2230, 3699, 1810, 1252,   37,\n",
       "         3153, 2561, 4419, 3474,   17]),\n",
       " 'category': 'closed_qa'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_closed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

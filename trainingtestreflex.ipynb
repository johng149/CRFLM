{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.model import CustomModelNoDownsize as CustomModel\n",
    "from models.model import CRFModelV2 as CRFModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenmonster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_file = \"english-8000-balanced-v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = tokenmonster.load_multiprocess_safe(tokenizer_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_vocab_size is 8000, so largest valid index is 7999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = initial_vocab_size # max valid index is now 8000\n",
    "eos_idx = initial_vocab_size + 1 # max valid index is now 8001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = initial_vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_len = 256\n",
    "context_len = 512\n",
    "answer_len = 100\n",
    "assert context_len >= answer_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 512\n",
    "num_heads = 8\n",
    "num_helix_layers = 1\n",
    "num_single_strand_layers = 1\n",
    "phm_factor = 4\n",
    "lm_head_phm_factor = 2\n",
    "beam = 32\n",
    "low_rank = 16\n",
    "batch_size = 25\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"{checkpoint_dir}/crf_model_reflex.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train_file = \"data/squad_train\"\n",
    "dolly_test_file = \"data/closed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = load_from_disk(squad_train_file)\n",
    "dolly = load_from_disk(dolly_test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, question_key, context_key, answer_key):\n",
    "    \"\"\"\n",
    "    Each batch has 3 elements: instruction, context, response\n",
    "    However since their lengths may vary, we need to pad them.\n",
    "\n",
    "    For response, must ensure that we add eos token and then begin padding.\n",
    "    \"\"\"\n",
    "    contexts = []\n",
    "    answers = []\n",
    "\n",
    "    for elem in batch:\n",
    "        i = elem[question_key]\n",
    "        c = elem[context_key]\n",
    "        r = elem[answer_key]\n",
    "\n",
    "        c = torch.cat((i, c))\n",
    "        contexts.append(c)\n",
    "        answers.append(r)\n",
    "\n",
    "\n",
    "    # Pad contexts to context_len\n",
    "    contexts = [pad(c, (0, (context_len+question_len) - len(c)), value=pad_idx) for c in contexts]\n",
    "\n",
    "    # Pad responses to answer_len\n",
    "    # though first making sure that eos token is added to end of each response\n",
    "    # eos_append = torch.tensor([eos_idx])\n",
    "    # answers = [torch.cat((r[:answer_len-1], eos_append)) for r in answers]\n",
    "    eos_append = torch.tensor([eos_idx, eos_idx])\n",
    "    answers = [torch.cat((r[:answer_len-2], eos_append)) for r in answers]\n",
    "    answers = [pad(r, (0, answer_len - len(r)), value=pad_idx) for r in answers]\n",
    "\n",
    "    return torch.stack(contexts), torch.stack(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dolly_collate_fn(batch):\n",
    "    return collate_fn(batch, \"instruction\", \"context\", \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squad_collate_fn(batch):\n",
    "    return collate_fn(batch, \"question\", \"context\", \"answers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollyDataloader = DataLoader(dolly, batch_size=batch_size, shuffle=True, collate_fn=dolly_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "squadDataloader = DataLoader(squad, batch_size=batch_size, shuffle=True, collate_fn=squad_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in squadDataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(losses, model, crf, optm, tensorboard_log_dir):\n",
    "    # first check to see if checkpoint dir exists, if not, create it\n",
    "    if not os.path.exists(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "    torch.save({\n",
    "    'epoch': len(losses),\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optm.state_dict(),\n",
    "    'loss': losses[-1],\n",
    "    'losses': losses,\n",
    "    'crf_state_dict': crf.state_dict(),\n",
    "    'model_kwargs': model.kwargs,\n",
    "    'crf_kwargs': crf.kwargs,\n",
    "    'tensorboard_log_dir': tensorboard_log_dir\n",
    "    }, path)\n",
    "def load_checkpoint(map_location=None):\n",
    "    checkpoint = torch.load(path, map_location=map_location)\n",
    "    model = CustomModel(**checkpoint['model_kwargs'])\n",
    "    crf = CRFModel(model=model, **checkpoint['crf_kwargs'])\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    crf.load_state_dict(checkpoint['crf_state_dict'])\n",
    "    model = model.to(device)\n",
    "    crf = crf.to(device)\n",
    "    optm = torch.optim.Adam(crf.parameters())\n",
    "    optm.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    losses = checkpoint['losses']\n",
    "    log_dir = checkpoint['tensorboard_log_dir']\n",
    "    return losses, model, crf, optm, log_dir\n",
    "def try_loading():\n",
    "    \"\"\"\n",
    "    First try to load the model, if it doesn't exist, create one\n",
    "    based on the parameters specified above\n",
    "    \"\"\"\n",
    "    try:\n",
    "        losses, model, crf, optm, log_dir = load_checkpoint()\n",
    "        print(f\"Resuming, have seen {len(losses)} epochs\")\n",
    "        print(f\"Have {sum(p.numel() for p in crf.parameters() if p.requires_grad)} trainable parameters\")\n",
    "        print(f\"Logging to {log_dir}\")\n",
    "        return losses, model, crf, optm, log_dir\n",
    "    except FileNotFoundError:\n",
    "        # couldn't find model, probably because it doesn't exist\n",
    "        print(\"Couldn't find model, creating new one\")\n",
    "        model = CustomModel(embedding_dim, num_heads, vocab_size, num_helix_layers=num_helix_layers, num_single_strand_layers=num_single_strand_layers, phm_factor=phm_factor, lm_head_phm_factor=lm_head_phm_factor)\n",
    "        model = model.to(device)\n",
    "        crf = CRFModel(model, vocab_size, beam, low_rank, pad_idx)\n",
    "        crf = crf.to(device)\n",
    "        optm = Adam(crf.parameters(), lr=0.001)\n",
    "        losses = []\n",
    "        print(f\"Have {sum(p.numel() for p in crf.parameters() if p.requires_grad)} trainable parameters\")\n",
    "        # create a string to identify this model for tensorboard logging\n",
    "        now = datetime.datetime.now()\n",
    "        log_dir = f\"runs/run_at_{now.strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "        print(f\"Logging to {log_dir}\")\n",
    "        return losses, model, crf, optm, log_dir\n",
    "    except RuntimeError:\n",
    "        # probably because model was saved on gpu and now we're using cpu\n",
    "        # so can still load it, but need to specify map_location\n",
    "        print(\"Model found but was saved on gpu, attempting to load on cpu\")\n",
    "        losses, model, crf, optm, log_dir = load_checkpoint(map_location='cpu')\n",
    "        print(f\"Resuming, have seen {len(losses)} epochs\")\n",
    "        print(f\"Have {sum(p.numel() for p in crf.parameters() if p.requires_grad)} trainable parameters\")\n",
    "        print(f\"Logging to {log_dir}\")\n",
    "        return losses, model, crf, optm, log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loss_functions.unlikelihood_loss import unlikelihood_loss\n",
    "from loss_functions.nag_bert_loss import nag_bert_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3\n",
    "nll_loss_weight = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find model, creating new one\n",
      "Have 10783810 trainable parameters\n",
      "Logging to runs/run_at_2023-11-26_08-06-41\n"
     ]
    }
   ],
   "source": [
    "losses, model, crf, optm, log_dir = try_loading()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(logits, targets, crf_losses):\n",
    "    bt_size, _ = targets.shape\n",
    "    cross_entropy_loss = torch.nn.functional.cross_entropy(logits.reshape(-1, vocab_size), targets.view(-1), ignore_index=pad_idx, reduction='none').view(bt_size, answer_len)\n",
    "    target_padding_matrix = ~targets.eq(pad_idx)\n",
    "    target_padding_matrix = target_padding_matrix.type(cross_entropy_loss.type())\n",
    "    cross_entropy_loss = cross_entropy_loss * target_padding_matrix\n",
    "    summed_loss = cross_entropy_loss.sum(dim = -1)\n",
    "    one_step_train_loss = crf_losses + nll_loss_weight * summed_loss\n",
    "    scaled_train_loss = torch.sum(one_step_train_loss) / torch.sum(target_padding_matrix)\n",
    "    return scaled_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(c_sample):\n",
    "    with torch.no_grad():\n",
    "        model_input_sample = torch.full_like(r_sample, pad_idx)\n",
    "        scores, tokens = crf.inference(c_sample, model_input_sample)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_decode(tokens):\n",
    "    # differs from vocab.decode in that it stops decoding when it sees eos_idx or pad_idx\n",
    "    filtered_tokens = []\n",
    "    for t in tokens:\n",
    "        if t == eos_idx or t == pad_idx:\n",
    "            break\n",
    "        else:\n",
    "            filtered_tokens.append(t)\n",
    "    return vocab.decode(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import adam optimizer\n",
    "from torch.optim import Adam\n",
    "optm = Adam(crf.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "squadIter = iter(squadDataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have seen 0 epochs, training for 22000 more for a total of 22000\n"
     ]
    }
   ],
   "source": [
    "total_epochs = 22000\n",
    "seen = len(losses)\n",
    "epochs = total_epochs - seen\n",
    "print(f\"Have seen {seen} epochs, training for {epochs} more for a total of {total_epochs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7112a79798cd45eea8c9568e7d70ae9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(range(epochs))\n",
    "for epoch in pbar:\n",
    "    try:\n",
    "        batch = next(squadIter)\n",
    "    except StopIteration:\n",
    "        squadIter = iter(squadDataloader)\n",
    "        batch = next(squadIter)\n",
    "    c, r = batch\n",
    "    c = c.to(device)\n",
    "    r = r.to(device)\n",
    "    model_input = torch.full_like(r, pad_idx)\n",
    "    logits, crf_losses = crf(c, model_input, r)\n",
    "    loss = custom_loss(logits, r, crf_losses)\n",
    "    # model_input is full of pad_idx, but we also want to train the model\n",
    "    # to be able to correct itself (reflection)\n",
    "    with torch.no_grad():\n",
    "        _, model_prediction = crf.inference(c, model_input)\n",
    "    logits_reflection, crf_losses_reflection = crf(c, model_prediction, r)\n",
    "    loss_reflection = custom_loss(logits_reflection, r, crf_losses_reflection)\n",
    "    loss = loss + loss_reflection\n",
    "    optm.zero_grad()\n",
    "    loss.backward()\n",
    "    optm.step()\n",
    "    losses.append(loss.item())\n",
    "    writer.add_scalar(\"Loss/train\", losses[-1], epoch + seen)\n",
    "    pbar.set_description(f\"Epoch {epoch + seen} of {total_epochs}, loss: {loss.item()}\")\n",
    "    if epoch % 20 == 0:\n",
    "        save_checkpoint(losses, model, crf, optm, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_checkpoint(losses, model, crf, optm, log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take sample of c and r to test model generation\n",
    "sample_i = 9\n",
    "assert sample_i < batch_size\n",
    "c_sample = c[sample_i:sample_i+1]\n",
    "r_sample = r[sample_i:sample_i+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = inference(c_sample).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[332,\n",
       " 2201,\n",
       " 65,\n",
       " 457,\n",
       " 45,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 8001,\n",
       " 668,\n",
       " 36,\n",
       " 660,\n",
       " 37,\n",
       " 660,\n",
       " 37,\n",
       " 660,\n",
       " 37,\n",
       " 660,\n",
       " 1219,\n",
       " 715,\n",
       " 1219,\n",
       " 715,\n",
       " 1219,\n",
       " 715,\n",
       " 1219,\n",
       " 715,\n",
       " 1219,\n",
       " 715,\n",
       " 1219,\n",
       " 715,\n",
       " 1219,\n",
       " 715,\n",
       " 1219,\n",
       " 715,\n",
       " 37,\n",
       " 715,\n",
       " 130,\n",
       " 8001,\n",
       " 177,\n",
       " 128,\n",
       " 311,\n",
       " 8001,\n",
       " 177,\n",
       " 4950,\n",
       " 1972,\n",
       " 332,\n",
       " 4950,\n",
       " 1978,\n",
       " 332,\n",
       " 4950,\n",
       " 1978,\n",
       " 1998,\n",
       " 2004,\n",
       " 7422,\n",
       " 4363,\n",
       " 2804]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What types of annelids have evolved jaws?Feeding structures in the mouth region vary widely, and have little correlation with the animals\\' diets. Many polychaetes have a muscular pharynx that can be everted (turned inside out to extend it). In these animals the foremost few segments often lack septa so that, when the muscles in these segments contract, the sharp increase in fluid pressure from all these segments everts the pharynx very quickly. Two families, the Eunicidae and Phyllodocidae, have evolved jaws, which can be used for seizing prey, biting off pieces of vegetation, or grasping dead and decaying matter. On the other hand, some predatory polychaetes have neither jaws nor eversible pharynges. Selective deposit feeders generally live in tubes on the sea-floor and use palps to find food particles in the sediment and then wipe them into their mouths. Filter feeders use \"crowns\" of palps covered in cilia that wash food particles towards their mouths. Non-selective deposit feeders ingest soil or marine sediments via mouths that are generally unspecialized. Some clitellates have sticky pads in the roofs of their mouths, and some of these can evert the pads to capture prey. Leeches often have an eversible proboscis, or a muscular pharynx with two or three teeth.'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.decode(c_sample.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Archunia'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_decode(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eunicidae and Phyllodocidae'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.decode(r_sample.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_input = 'On what date is the Feat of Transfiguration celebrated?Ecclesiam suam was given at St. Peter\\'s, Rome, on the Feast of the Transfiguration, 6 August 1964, the second year of his Pontificate. It is considered an important document, identifying the Catholic Church with the Body of Christ. A later Council document Lumen Gentium stated that the Church subsists in the Body of Christ, raising questions as to the difference between \"is\" and \"subsists in\". Paul VI appealed to \"all people of good will\" and discussed necessary dialogues within the Church and between the Churches and with atheism.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = vocab.tokenize(custom_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 332,  772, 2777, 2291, 4165,   36,  233,   37, 1413,  769,   36,\n",
       "       3604,   37,  705,   37,  716, 3804, 6446,   48,   34,  332,  688,\n",
       "         37, 1351,  500,  348,  806,  348, 1835, 3242,  655, 3761, 1653,\n",
       "        387,  275,  290,  791,  445,   15, 4287,   36,  704,   37, 1278,\n",
       "       4280,   36, 3604,   37,  705,   37,  716, 3804,   15,  216, 5497,\n",
       "       1234,   23,   15, 7222, 2796, 4277,   36, 1665,  509,  392,  992,\n",
       "       1003, 3312, 7015, 7582, 5762,   15, 5870, 4694, 6871, 5502, 6232,\n",
       "         36, 2232,  769, 5501, 1914, 3325, 6294, 5762, 1950, 1086,   36,\n",
       "       1473,  509,  517, 4441, 6133, 5502, 2705, 2072, 4153,   36, 2232,\n",
       "        769, 5501,   15, 1683, 2110, 6683, 3073, 1788, 7950,  580,  729,\n",
       "       2806,  580, 2705, 2072,  727,  850,  777,  516,   38,  828, 3881,\n",
       "       2933,  580, 1256, 4308,  769, 2391, 2783, 2806, 6497, 6631, 1388,\n",
       "         37, 1569,  515,   63, 7258, 5502, 1263, 7345, 5502,  388, 5654,\n",
       "        655,   37, 1498,   37,  800,   17], dtype=uint16)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded from uint16 to int32\n",
    "encoded = encoded.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = torch.tensor(encoded).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_output = inference(encoded.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 332, 1585, 1227, 1412,  443, 1233,   19, 1412,  443, 1412,  443, 1412,\n",
       "          443, 1412,  443, 8001, 8001, 8001, 8001, 8001, 8001, 8001, 8001, 8001,\n",
       "         8001, 8001, 8001, 8001, 8001, 8001, 8001, 8001, 8001, 8001, 8001, 8001,\n",
       "         8001, 8001, 8001, 8001,  643,   37,  643,   37,  643,   37,  643,   37,\n",
       "          643,   37,  643,   37,  643,   37,  643,   37,  643,   37,  643,   37,\n",
       "          643,   37,  643,   37,  643,   37,  643,   37,  643,   37,  643,  400,\n",
       "           36,  715,   37,  715,   37,  715,  483,  332, 1423,  715,  475,  483,\n",
       "          715,  475,  483,  715,  475,  398,  506, 2974,  352, 2920, 8001, 4454,\n",
       "         4454,   90, 7393,  143]], device='cuda:0')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'May 189 early 1950 early early early early'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "special_decode(custom_output.tolist()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
